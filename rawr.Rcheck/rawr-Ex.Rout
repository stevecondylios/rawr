
R version 3.6.0 (2019-04-26) -- "Planting of a Tree"
Copyright (C) 2019 The R Foundation for Statistical Computing
Platform: x86_64-apple-darwin15.6.0 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> pkgname <- "rawr"
> source(file.path(R.home("share"), "R", "examples-header.R"))
> options(warn = 1)
> base::assign(".ExTimings", "rawr-Ex.timings", pos = 'CheckExEnv')
> base::cat("name\tuser\tsystem\telapsed\n", file=base::get(".ExTimings", pos = 'CheckExEnv'))
> base::assign(".format_ptime",
+ function(x) {
+   if(!is.na(x[4L])) x[1L] <- x[1L] + x[4L]
+   if(!is.na(x[5L])) x[2L] <- x[2L] + x[5L]
+   options(OutDec = '.')
+   format(x[1L:3L], digits = 7L)
+ },
+ pos = 'CheckExEnv')
> 
> ### * </HEADER>
> library('rawr')
> 
> base::assign(".oldSearch", base::search(), pos = 'CheckExEnv')
> base::assign(".old_wd", base::getwd(), pos = 'CheckExEnv')
> cleanEx()
> nameEx("blogdown")
> ### * blogdown
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: blogdown
> ### Title: Retrieve raw R code from a blogdown web page
> ### Aliases: blogdown
> 
> ### ** Examples
> 
> library(dplyr)

Attaching package: ‘dplyr’

The following objects are masked from ‘package:stats’:

    filter, lag

The following objects are masked from ‘package:base’:

    intersect, setdiff, setequal, union

> blogdown("https://www.jtimm.net/2019/04/14/lexical-change-procrustes/")
[1] "library(tidyverse)\n\nsetwd(local_dir)\r\ntfms_mats <- readRDS('tfms_mats.rds')\n\nall_terms <-Reduce(intersect, \r\n                   lapply(tfms_mats, rownames)) \r\n\r\ntfms_trimmed <- lapply(1:8, function (x)\r\n  tfms_mats[[x]][rownames(tfms_mats[[x]]) %in% all_terms,])\r\nnames(tfms_trimmed) <- names(tfms_mats)\n\nsetwd(local_freq)\r\nfreqs_by_gen <- readRDS('freqs_by_gen.rds')\n\nsample <- c('GRASP', 'SIGNIFICANT', 'COMMITMENT', 'HOPE')\r\n\r\nfreqs_by_gen %>%\r\n  filter(form %in% sample) %>%\r\n  \r\n  ggplot(aes(x = quarter, y = ppm, \r\n             color = form, group = form)) +\r\n  geom_line(size = 1.5) +\r\n  ggthemes::scale_color_stata()+\r\n  facet_wrap(~form, scales = 'free_y', ncol=2) +\r\n  labs(title=\"Historical frequencies of some forms on the move\") +\r\n  theme(legend.position=\"none\",\r\n        axis.text.x=element_text(angle=45, \r\n                                 hjust=0.5, vjust=0.5))\n\nneighbors\n\nLSAfun\n\nsearch <- toupper('significant')\r\nnns <- lapply(tfms_trimmed, LSAfun::neighbors, x = search , n = 10)\r\n#disability, disorder, CELL, quit, significant, \n\nstrip_syns <- function (x) {\r\n  lapply(1:length(x), function(y)  \r\n    cbind(form = as.character(names(x[[y]])), \r\n          quarter = names(x[y]), \r\n          data.frame(sim = x[[y]], row.names=NULL)) ) %>%\r\n    bind_rows()}\n\nsyns <- nns %>% \r\n  strip_syns() %>%\r\n  inner_join(freqs_by_gen) %>%\r\n  mutate(ppm = round(ppm, 1), sim = round(sim,3)) %>%\r\n  select(-freq) %>%\r\n  group_by(quarter) %>%\r\n  arrange(desc(sim))%>%\r\n  ungroup()\n\ngridExtra\n\ng <- list(length(tfms_mats))\r\ntt <- gridExtra::ttheme_default(base_size = 6.75)\r\n\r\nfor (i in 1:length(tfms_mats)) {\r\n  g[[i]] <- syns %>% \r\n    filter (quarter == names(tfms_mats[i])) %>%\r\n    rename(!!names(tfms_mats[i]) := form) %>% \r\n    select(-quarter)%>%\r\n    gridExtra::tableGrob(rows=NULL, theme = tt) }\r\n\r\ngridExtra::grid.arrange(grobs = g, nrow = 2)\n\nprocrustes\n\nvegan\n\nprocrustes_clean <- lapply(1:7, function (x) {\r\n  \r\n  pc <- vegan::procrustes (X = tfms_trimmed[[8]], \r\n                           Y = tfms_trimmed[[x]])\r\n  pc <- pc$Yrot\r\n  dimnames(pc) <-list(rownames(tfms_trimmed[[8]]), \r\n                     c(1:250))\r\n  pc } )\r\n\r\nprocrustes_clean[[8]] <- tfms_trimmed[[8]]\r\nnames(procrustes_clean) <- names(tfms_mats)\n\ngens <- c(\"[1833,1858)\", \"[1883,1908)\", \r\n          \"[1933,1958)\", \"[1983,2008]\")\n\nplot_syns <- syns %>%\r\n  filter(!form %in% search & quarter %in% gens) %>%\r\n  group_by(quarter) %>%\r\n  slice(1:15) %>%\r\n  ungroup() %>%\r\n  select(form) %>%\r\n  distinct()\n\nsyn_modern <- tfms_trimmed[[8]][rownames(tfms_trimmed[[8]]) %in%\r\n                                  plot_syns$form,]\n\nterm_proc <- lapply(procrustes_clean[c(2,4,6,8)], \r\n                    function (x) x[search,]) %>%\r\n  bind_rows() %>% t()\n\nfull <- rbind(term_proc, syn_modern)\n\npca <- prcomp(full)$x[,1:2] %>% \r\n  data.frame() %>% \r\n  rownames_to_column() %>%\r\n  mutate(cs = ifelse(grepl('\\\\[', rowname), 'steelblue', 'black')) %>%\r\n  mutate(sz = ifelse(cs == 'steelblue', 3.5, 2.5))\n\nset.seed(99)\r\n#Hack to build arrows in viz.\r\nto_end <- pca %>% slice(1:4) \r\nfor (i in 1:(nrow(to_end)-1)) {\r\n  to_end$PC3[i] <- to_end$PC1[i+1]\r\n  to_end$PC4[i] <- to_end$PC2[i+1] }\r\n\r\nggplot(pca, aes(x=PC1, y=PC2))+\r\n  geom_point(color = 'darkgray', size = 1)+\r\n  ggrepel::geom_text_repel(\r\n    data  = pca, label = pca$rowname,\r\n    color = pca$cs, segment.size = .25,\r\n    direction = \"y\", hjust = 0, size = pca$sz,\r\n    segment.alpha = .25) +\r\n  geom_segment(data = to_end %>% slice(1:3), \r\n               aes(x=PC1, y=PC2, xend =PC3, yend = PC4),\r\n               color = 'steelblue',\r\n               size = .6, linetype = 2,\r\n               arrow = arrow(length=unit(0.30,\"cm\"), \r\n                             type = \"closed\",\r\n                             angle = 25))+\r\n\r\n  ggthemes::theme_fivethirtyeight()  +\r\n  ggtitle(paste0(search, ' in nearest-neighbor space historically')) +\r\n  theme(axis.title.x=element_blank(),\r\n        axis.text.x=element_blank(),\r\n        axis.title.y=element_blank(),\r\n        axis.text.y=element_blank(),\r\n        plot.title = element_text(size=12))\n\nsim_deltas <- sapply(rownames(procrustes_clean[[8]]), function (x) \r\n  lsa::cosine(procrustes_clean[[\"[1883,1908)\"]][x,],\r\n              procrustes_clean[[\"[1983,2008]\"]][x,]) ) %>%\r\n  #Clean -- \r\n  as.tibble() %>% \r\n  rownames_to_column(var = 'form') %>%\r\n  mutate(value = round(value, 3)) %>%\r\n  arrange(desc(value)) %>%\r\n  rename(sim_t1_t2 = value)\n\nfreq_deltas <- freqs_by_gen %>%\r\n  filter(quarter %in% c(\"[1883,1908)\", \"[1983,2008]\") &\r\n           form %in% rownames(procrustes_clean[[8]])) %>%\r\n  select(-freq) %>%\r\n  spread(quarter, ppm) %>%\r\n  mutate(log_freq_t1_t2 = round(log(`[1983,2008]`/`[1883,1908)`),3)) %>%\r\n  inner_join(sim_deltas) \r\n\r\nfreq_deltas %>% arrange(sim_t1_t2) %>% slice(1:6) %>% knitr::kable()\n\nfreq_deltas %>%  \r\n  ggplot(aes(x = log_freq_t1_t2, y =sim_t1_t2)) +\r\n  geom_point(size = .25)+\r\n  geom_smooth(method=\"loess\", se=T, color = 'steelblue')+\r\n  ggtitle('Delta frequency & semantic dispalcement: [1883,1908) to [1983,2008]')"
> 
> # Same as above but provided to cat for easy viewing
> blogdown("https://www.jtimm.net/2019/04/14/lexical-change-procrustes/")  %>%
+   cat
library(tidyverse)

setwd(local_dir)
tfms_mats <- readRDS('tfms_mats.rds')

all_terms <-Reduce(intersect, 
                   lapply(tfms_mats, rownames)) 

tfms_trimmed <- lapply(1:8, function (x)
  tfms_mats[[x]][rownames(tfms_mats[[x]]) %in% all_terms,])
names(tfms_trimmed) <- names(tfms_mats)

setwd(local_freq)
freqs_by_gen <- readRDS('freqs_by_gen.rds')

sample <- c('GRASP', 'SIGNIFICANT', 'COMMITMENT', 'HOPE')

freqs_by_gen %>%
  filter(form %in% sample) %>%
  
  ggplot(aes(x = quarter, y = ppm, 
             color = form, group = form)) +
  geom_line(size = 1.5) +
  ggthemes::scale_color_stata()+
  facet_wrap(~form, scales = 'free_y', ncol=2) +
  labs(title="Historical frequencies of some forms on the move") +
  theme(legend.position="none",
        axis.text.x=element_text(angle=45, 
                                 hjust=0.5, vjust=0.5))

neighbors

LSAfun

search <- toupper('significant')
nns <- lapply(tfms_trimmed, LSAfun::neighbors, x = search , n = 10)
#disability, disorder, CELL, quit, significant, 

strip_syns <- function (x) {
  lapply(1:length(x), function(y)  
    cbind(form = as.character(names(x[[y]])), 
          quarter = names(x[y]), 
          data.frame(sim = x[[y]], row.names=NULL)) ) %>%
    bind_rows()}

syns <- nns %>% 
  strip_syns() %>%
  inner_join(freqs_by_gen) %>%
  mutate(ppm = round(ppm, 1), sim = round(sim,3)) %>%
  select(-freq) %>%
  group_by(quarter) %>%
  arrange(desc(sim))%>%
  ungroup()

gridExtra

g <- list(length(tfms_mats))
tt <- gridExtra::ttheme_default(base_size = 6.75)

for (i in 1:length(tfms_mats)) {
  g[[i]] <- syns %>% 
    filter (quarter == names(tfms_mats[i])) %>%
    rename(!!names(tfms_mats[i]) := form) %>% 
    select(-quarter)%>%
    gridExtra::tableGrob(rows=NULL, theme = tt) }

gridExtra::grid.arrange(grobs = g, nrow = 2)

procrustes

vegan

procrustes_clean <- lapply(1:7, function (x) {
  
  pc <- vegan::procrustes (X = tfms_trimmed[[8]], 
                           Y = tfms_trimmed[[x]])
  pc <- pc$Yrot
  dimnames(pc) <-list(rownames(tfms_trimmed[[8]]), 
                     c(1:250))
  pc } )

procrustes_clean[[8]] <- tfms_trimmed[[8]]
names(procrustes_clean) <- names(tfms_mats)

gens <- c("[1833,1858)", "[1883,1908)", 
          "[1933,1958)", "[1983,2008]")

plot_syns <- syns %>%
  filter(!form %in% search & quarter %in% gens) %>%
  group_by(quarter) %>%
  slice(1:15) %>%
  ungroup() %>%
  select(form) %>%
  distinct()

syn_modern <- tfms_trimmed[[8]][rownames(tfms_trimmed[[8]]) %in%
                                  plot_syns$form,]

term_proc <- lapply(procrustes_clean[c(2,4,6,8)], 
                    function (x) x[search,]) %>%
  bind_rows() %>% t()

full <- rbind(term_proc, syn_modern)

pca <- prcomp(full)$x[,1:2] %>% 
  data.frame() %>% 
  rownames_to_column() %>%
  mutate(cs = ifelse(grepl('\\[', rowname), 'steelblue', 'black')) %>%
  mutate(sz = ifelse(cs == 'steelblue', 3.5, 2.5))

set.seed(99)
#Hack to build arrows in viz.
to_end <- pca %>% slice(1:4) 
for (i in 1:(nrow(to_end)-1)) {
  to_end$PC3[i] <- to_end$PC1[i+1]
  to_end$PC4[i] <- to_end$PC2[i+1] }

ggplot(pca, aes(x=PC1, y=PC2))+
  geom_point(color = 'darkgray', size = 1)+
  ggrepel::geom_text_repel(
    data  = pca, label = pca$rowname,
    color = pca$cs, segment.size = .25,
    direction = "y", hjust = 0, size = pca$sz,
    segment.alpha = .25) +
  geom_segment(data = to_end %>% slice(1:3), 
               aes(x=PC1, y=PC2, xend =PC3, yend = PC4),
               color = 'steelblue',
               size = .6, linetype = 2,
               arrow = arrow(length=unit(0.30,"cm"), 
                             type = "closed",
                             angle = 25))+

  ggthemes::theme_fivethirtyeight()  +
  ggtitle(paste0(search, ' in nearest-neighbor space historically')) +
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        plot.title = element_text(size=12))

sim_deltas <- sapply(rownames(procrustes_clean[[8]]), function (x) 
  lsa::cosine(procrustes_clean[["[1883,1908)"]][x,],
              procrustes_clean[["[1983,2008]"]][x,]) ) %>%
  #Clean -- 
  as.tibble() %>% 
  rownames_to_column(var = 'form') %>%
  mutate(value = round(value, 3)) %>%
  arrange(desc(value)) %>%
  rename(sim_t1_t2 = value)

freq_deltas <- freqs_by_gen %>%
  filter(quarter %in% c("[1883,1908)", "[1983,2008]") &
           form %in% rownames(procrustes_clean[[8]])) %>%
  select(-freq) %>%
  spread(quarter, ppm) %>%
  mutate(log_freq_t1_t2 = round(log(`[1983,2008]`/`[1883,1908)`),3)) %>%
  inner_join(sim_deltas) 

freq_deltas %>% arrange(sim_t1_t2) %>% slice(1:6) %>% knitr::kable()

freq_deltas %>%  
  ggplot(aes(x = log_freq_t1_t2, y =sim_t1_t2)) +
  geom_point(size = .25)+
  geom_smooth(method="loess", se=T, color = 'steelblue')+
  ggtitle('Delta frequency & semantic dispalcement: [1883,1908) to [1983,2008]')> 
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("blogdown", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()

detaching ‘package:dplyr’

> nameEx("datacamp")
> ### * datacamp
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: datacamp
> ### Title: Retrieve raw R code from a datacamp tutorial
> ### Aliases: datacamp
> 
> ### ** Examples
> 
> 
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("datacamp", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("github")
> ### * github
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: github
> ### Title: Retrieve raw R code from an .R file hosted on github website
> ### Aliases: github
> 
> ### ** Examples
> 
> library(dplyr)

Attaching package: ‘dplyr’

The following objects are masked from ‘package:stats’:

    filter, lag

The following objects are masked from ‘package:base’:

    intersect, setdiff, setequal, union

> github("https://github.com/hadley/vis-eda/blob/master/travel.R")
[1] "library(tidyverse)\n\nlibrary(lubridate)\n\nlibrary(httr)\n\nsource(\"cache.R\")\n\n\n\n# ENDLESS SCREAMING -------------------------------------------------------\n\n\n\nauth <- authenticate(\n\n  \"h.wickham@gmail.com\",\n\n  rstudioapi::askForPassword(\"tripit password\"),\n\n  \"basic\"\n\n)\n\n\n\nGET_tripit <- function(url, query = list(), ...) {\n\n  default_query <- list(\n\n    format = \"json\",\n\n    page_size = 500\n\n  )\n\n  query <- modifyList(default_query, query)\n\n\n\n  r <- GET(url, auth, query = query, ...)\n\n  stop_for_status(r)\n\n  content(r)\n\n}\n\n\n\nlist_trips <- function(page_num = 1) {\n\n  GET_tripit(\n\n    \"https://api.tripit.com/v1/list/trip/past/true\",\n\n    query = list(page_num = page_num)\n\n  )\n\n}\n\n\n\n# Data rectangling -------------------------------------------------------\n\n\n\ntrips_json <- cache(\"trips-json\", list_trips()$Trip)\n\nstr(trips_json[[1]])\n\n\n\naddress <- trips_json %>% map(\"PrimaryLocationAddress\")\n\n\n\ntrips <- tibble(\n\n  id =      trips_json %>% map_chr(\"id\"),\n\n  start =   trips_json %>% map_chr(\"start_date\") %>% parse_date(),\n\n  end =     trips_json %>% map_chr(\"end_date\") %>% parse_date(),\n\n  lat =     address %>% map_chr(\"latitude\", .default = NA) %>% parse_double(),\n\n  lon =     address %>% map_chr(\"longitude\", .default = NA) %>% parse_double(),\n\n  city =    address %>% map_chr(\"city\", .default = NA),\n\n  country = address %>% map_chr(\"country\", .default = NA)\n\n)\n\ntrips\n\ntrips %>% write_csv(\"trips.csv\")\n\n\n\n# Visualisation -------------------------------------------------------\n\n\n\nggplot(trips, aes(y = country)) +\n\n  geom_segment(aes(x = start, xend = end, yend = country))\n\n\n\ntrips2 <- trips %>%\n\n  mutate(\n\n    start_day = update(start, year = 2010),\n\n    end_day = update(end, year = 2010),\n\n    year = year(start)\n\n  )\n\nggplot(trips2) +\n\n  geom_segment(aes(x = start_day, xend = end_day, y = year, yend = year))\n\n\n\ntrips2 %>%\n\n  filter(start_day < end_day) %>%\n\n  ggplot() +\n\n  geom_segment(aes(x = start_day, xend = end_day, y = year, yend = year))\n\n\n\ntrips2 %>%\n\n  filter(start_day < end_day) %>%\n\n  ggplot() +\n\n  geom_segment(aes(x = start_day, xend = end_day, y = year, yend = year), size = 10) +\n\n  scale_y_continuous(breaks = 2000 + seq(7, 17, by = 2)) +\n\n  scale_x_date(date_labels = \"%b\")\n\n\n\ntrips2 %>%\n\n  filter(start_day < end_day) %>%\n\n  ggplot() +\n\n  geom_segment(aes(x = start_day, xend = end_day, y = year, yend = year, colour = country), size = 10) +\n\n  scale_y_continuous(breaks = 2000 + seq(7, 17, by = 2)) +\n\n  scale_x_date(date_labels = \"%b\")\n\n\n\ntrips2 %>%\n\n  filter(start_day < end_day) %>%\n\n  ggplot() +\n\n  geom_segment(aes(x = start_day, xend = end_day, y = year, yend = year, colour = forcats::fct_lump(country, 8)), size = 10) +\n\n  scale_y_continuous(breaks = 2000 + seq(7, 17, by = 2)) +\n\n  scale_x_date(date_labels = \"%b\")\n\n\n\n# I wish there was a way to set the colour of one country\n\n# Would be nice to show continent instead?\n\n\n\n# Exploration vs. exposition ----------------------------------------------\n\n\n\nus_totals <- trips %>%\n\n  filter(country == \"US\") %>%\n\n  group_by(city, lat, lon) %>%\n\n  summarise(n = n()) %>%\n\n  arrange(desc(n))\n\n\n\nggplot(us_totals, aes(lon, lat)) +\n\n  borders(\"state\") +\n\n  geom_point(aes(size = n))\n\n\n\nggplot(us_totals, aes(lon, lat)) +\n\n  borders(\"state\", fill = \"grey90\", colour = \"white\") +\n\n  geom_point(aes(size = n, colour = n)) +\n\n  ggrepel::geom_text_repel(aes(label = city)) +\n\n  scale_size_area(breaks = c(1, 5, 10, 14)) +\n\n  viridis::scale_color_viridis(breaks = c(1, 5, 10, 14), guide = \"legend\") +\n\n  scale_x_continuous(NULL, breaks = NULL) +\n\n  scale_y_continuous(NULL, breaks = NULL) +\n\n  coord_quickmap() +\n\n  labs(\n\n    title = \"Places I’ve visited in the US\",\n\n    caption = \"As captured by 'primary' address in TripIt\",\n\n    colour = \"Number of\\nvisits\",\n\n    size = \"Number of\\nvisits\"\n\n  ) +\n\n  hrbrthemes::theme_ipsum()\n\n\n\nggsave(\"travel-example.png\", width = 8, height = 5.5)"
> 
> # Same as above but provided to cat for easy viewing
> github("https://github.com/hadley/vis-eda/blob/master/travel.R") %>%
+   cat
library(tidyverse)

library(lubridate)

library(httr)

source("cache.R")



# ENDLESS SCREAMING -------------------------------------------------------



auth <- authenticate(

  "h.wickham@gmail.com",

  rstudioapi::askForPassword("tripit password"),

  "basic"

)



GET_tripit <- function(url, query = list(), ...) {

  default_query <- list(

    format = "json",

    page_size = 500

  )

  query <- modifyList(default_query, query)



  r <- GET(url, auth, query = query, ...)

  stop_for_status(r)

  content(r)

}



list_trips <- function(page_num = 1) {

  GET_tripit(

    "https://api.tripit.com/v1/list/trip/past/true",

    query = list(page_num = page_num)

  )

}



# Data rectangling -------------------------------------------------------



trips_json <- cache("trips-json", list_trips()$Trip)

str(trips_json[[1]])



address <- trips_json %>% map("PrimaryLocationAddress")



trips <- tibble(

  id =      trips_json %>% map_chr("id"),

  start =   trips_json %>% map_chr("start_date") %>% parse_date(),

  end =     trips_json %>% map_chr("end_date") %>% parse_date(),

  lat =     address %>% map_chr("latitude", .default = NA) %>% parse_double(),

  lon =     address %>% map_chr("longitude", .default = NA) %>% parse_double(),

  city =    address %>% map_chr("city", .default = NA),

  country = address %>% map_chr("country", .default = NA)

)

trips

trips %>% write_csv("trips.csv")



# Visualisation -------------------------------------------------------



ggplot(trips, aes(y = country)) +

  geom_segment(aes(x = start, xend = end, yend = country))



trips2 <- trips %>%

  mutate(

    start_day = update(start, year = 2010),

    end_day = update(end, year = 2010),

    year = year(start)

  )

ggplot(trips2) +

  geom_segment(aes(x = start_day, xend = end_day, y = year, yend = year))



trips2 %>%

  filter(start_day < end_day) %>%

  ggplot() +

  geom_segment(aes(x = start_day, xend = end_day, y = year, yend = year))



trips2 %>%

  filter(start_day < end_day) %>%

  ggplot() +

  geom_segment(aes(x = start_day, xend = end_day, y = year, yend = year), size = 10) +

  scale_y_continuous(breaks = 2000 + seq(7, 17, by = 2)) +

  scale_x_date(date_labels = "%b")



trips2 %>%

  filter(start_day < end_day) %>%

  ggplot() +

  geom_segment(aes(x = start_day, xend = end_day, y = year, yend = year, colour = country), size = 10) +

  scale_y_continuous(breaks = 2000 + seq(7, 17, by = 2)) +

  scale_x_date(date_labels = "%b")



trips2 %>%

  filter(start_day < end_day) %>%

  ggplot() +

  geom_segment(aes(x = start_day, xend = end_day, y = year, yend = year, colour = forcats::fct_lump(country, 8)), size = 10) +

  scale_y_continuous(breaks = 2000 + seq(7, 17, by = 2)) +

  scale_x_date(date_labels = "%b")



# I wish there was a way to set the colour of one country

# Would be nice to show continent instead?



# Exploration vs. exposition ----------------------------------------------



us_totals <- trips %>%

  filter(country == "US") %>%

  group_by(city, lat, lon) %>%

  summarise(n = n()) %>%

  arrange(desc(n))



ggplot(us_totals, aes(lon, lat)) +

  borders("state") +

  geom_point(aes(size = n))



ggplot(us_totals, aes(lon, lat)) +

  borders("state", fill = "grey90", colour = "white") +

  geom_point(aes(size = n, colour = n)) +

  ggrepel::geom_text_repel(aes(label = city)) +

  scale_size_area(breaks = c(1, 5, 10, 14)) +

  viridis::scale_color_viridis(breaks = c(1, 5, 10, 14), guide = "legend") +

  scale_x_continuous(NULL, breaks = NULL) +

  scale_y_continuous(NULL, breaks = NULL) +

  coord_quickmap() +

  labs(

    title = "Places I’ve visited in the US",

    caption = "As captured by 'primary' address in TripIt",

    colour = "Number of\nvisits",

    size = "Number of\nvisits"

  ) +

  hrbrthemes::theme_ipsum()



ggsave("travel-example.png", width = 8, height = 5.5)> 
> 
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("github", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()

detaching ‘package:dplyr’

> nameEx("identify_domain")
> ### * identify_domain
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: identify_domain
> ### Title: Identify the domain of the url
> ### Aliases: identify_domain
> 
> ### ** Examples
> 
> 
> test_domains <- c("https://github.com/hadley/vis-eda/blob/master/travel.R",
+ "https://www.datacamp.com/community/tutorials/sentiment-analysis-R",
+ "https://www.tidytextmining.com/sentiment.html",
+ "https://www.kaggle.com/vrtjso/mercari-eda-more-info-than-you-can-imagine")
> 
> identify_domain(test_domains)
[1] "github"         "datacamp"       "tidytextmining" "kaggle"        
> 
> 
> 
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("identify_domain", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("kaggle")
> ### * kaggle
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: kaggle
> ### Title: Retrieve raw R code from a kaggle notebook
> ### Aliases: kaggle
> 
> ### ** Examples
> 
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("kaggle", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("output_to_file")
> ### * output_to_file
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: output_to_file
> ### Title: Open contents in a new tempfile or file
> ### Aliases: output_to_file
> 
> ### ** Examples
> 
> 
> ## Not run: 
> ##D code_sample <- "#Sample code\nx <- 6\n2 * 2"
> ##D output_to_file(code_sample)
> ## End(Not run)
> 
> 
> 
> 
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("output_to_file", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("rawr")
> ### * rawr
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: rawr
> ### Title: Automatically identify website and retrieve raw R code from it
> ### Aliases: rawr
> 
> ### ** Examples
> 
> 
> 
> 
> 
> 
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("rawr", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("stackoverflow")
> ### * stackoverflow
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: stackoverflow
> ### Title: Retrieve raw R code from Stack Overflow website
> ### Aliases: stackoverflow
> 
> ### ** Examples
> 
> library(dplyr)

Attaching package: ‘dplyr’

The following objects are masked from ‘package:stats’:

    filter, lag

The following objects are masked from ‘package:base’:

    intersect, setdiff, setequal, union

> stackoverflow("https://stackoverflow.com/questions/58248102/date-input-dt-r-shiny")
[1] "library(shiny)\nlibrary(shinyjs)\nlibrary(shinythemes)\nlibrary(DT)\n\nGetMCATableMetadata <- function() {\n  fields <- c(\n    id = \"Id\",\n    month = \"Month of Account\",\n    due_date = \"Due Date of Submission\",\n    actual_date = \"Actual Date of Submission\"\n  )\n\n  result <- list(fields = fields)\n  return (result)\n}\n\n\n########################## CREATE, READ, UPDATE, DELETE #######################################\n#### CRUD\n\n\n\n# Find the next ID of a new record\nGetMCANextId <- function() {\n  if (exists(\"mcaresponses\") && nrow(mcaresponses) > 0) {\n    max(as.integer(rownames(mcaresponses))) + 1\n  } else {\n    return (1)\n  }\n}\n\n#C\nCreateData <- function(data) {\n  data <- CastData(data)\n  rownames(data) <- GetMCANextId()\n  if (exists(\"mcaresponses\")) {\n    mcaresponses <<- rbind(mcaresponses, data)\n  } else {\n    mcaresponses <<- data\n  }\n}\n\n#R\nReadData <- function() {\n  if (exists(\"mcaresponses\")) {\n    mcaresponses\n  }\n}\n\n#U\nUpdateData <- function(data) {\n  data <- CastData(data)\n  mcaresponses[row.names(mcaresponses) == row.names(data),] <<- data\n}\n\n#D\nDeleteData <- function(data) {\n  mcaresponses <<-\n    mcaresponses[row.names(mcaresponses) != unname(data[\"id\"]),]\n}\n\n#######################################################################################\n# Cast from Inputs to a one-row data.frame\n\nCastData <- function(data) {\n  datar <- data.frame(\n    month = data[\"month\"],\n    due_date = as.Date(data[[\"due_date\"]],\"dd-mm-yyyy\"),\n    actual_date = as.Date(data[[\"actual_date\"]],\"dd-mm-yyyy\")\n  )\n\n  rownames(datar) <- data[\"id\"]\n  return (datar)\n}\n\n\n\n\n# Return an empty, new record\nCreateDefaultRecord <- function() {\n  mydefault <-\n    CastData(list(\n      id = \"0\",\n      month = \"\", \n      due_date =\"\",\n      actual_date=\"\"\n\n    ))\n  return (mydefault)\n}\n\n# Fill the input fields with the values of the selected record in the table\nUpdateInputs <- function(data, session) {\n  updateTextInput(session, \"id\", value = unname(rownames(data)))\n  updateTextInput(session, \"month\", value = unname(data[\"month\"]))\n  updateDateInput(session, \"due_date\", value = as.Date(data[[\"due_date\"]],\"dd-mm-yyyy\"))\n  updateDateInput(session, \"actual_date\",value=as.Date(data[[\"actual_date\"]],\"dd-mm-yyyy\"))\n\n}\n\n\n\nui <- fluidPage(\n  #use shiny js to disable the ID field\n  shinyjs::useShinyjs(),\n  ##\n  #data table\n  DT::dataTableOutput(\"mcaresponses\", width = 800),\n\n  #input fields\n  tags$hr(),\n  shinyjs::disabled(textInput(\"id\", \"Id\", \"0\")),\n  textInput(\"month\", \"Month of Account\", \"\"),\n  dateInput(\"due_date\", label=\"Due Date of Submission\", format=\"dd-mm-yyyy\"),\n  dateInput(\"actual_date\", label=\"Actual Date of Submission\", format=\"dd-mm-yyyy\"),\n  #action buttons\n  actionButton(\"submit\", \"Submit\"),\n  actionButton(\"new\", \"New\"),\n  actionButton(\"delete\", \"Delete\")\n)\n\n\n\nserver <- function(input, output, session) {\n  # input fields are treated as a group\n  formData <- reactive({\n    sapply(names(GetMCATableMetadata()$fields), function(x)\n      input[[x]])\n  })\n\n  # Click \"Submit\" button -> save data\n  observeEvent(input$submit, {\n    if (input$id != \"0\") {\n      UpdateData(formData())\n    } else {\n      CreateData(formData())\n      UpdateInputs(CreateDefaultRecord(), session)\n    }\n  }, priority = 1)\n\n  # Press \"New\" button -> display empty record\n  observeEvent(input$new, {\n    UpdateInputs(CreateDefaultRecord(), session)\n  })\n\n  # Press \"Delete\" button -> delete from data\n  observeEvent(input$delete, {\n    DeleteData(formData())\n    UpdateInputs(CreateDefaultRecord(), session)\n  }, priority = 1)\n\n  # Select row in table -> show details in inputs\n  observeEvent(input$mcaresponses_rows_selected, {\n    if (length(input$mcaresponses_rows_selected) > 0) {\n      data <- ReadData()[input$mcaresponses_rows_selected,]\n      UpdateInputs(data, session)\n    }\n\n  })\n\n  # display table\n  output$mcaresponses <- DT::renderDataTable({\n    #update after submit is clicked\n    input$submit\n    #update after delete is clicked\n    input$delete\n    ReadData()\n    }, server = FALSE, selection = \"single\",\n  colnames = unname(GetMCATableMetadata()$fields)[-1])\n\n}\n\nshinyApp(ui = ui, server = server)\n\n\nsapply(names(GetMCATableMetadata()$fields), function(x) input[[x]])\n\n\nCastData\n\ndue_date = as.Date(as.numeric(data[\"due_date\"]), origin = \"1970-01-01\"),\nactual_date = as.Date(as.numeric(data[\"actual_date\"]), origin = \"1970-01-01\")\n\n\nDateInput\n\ndue_date\n\nactual_date\n\nDate\n\nupdateDateInput(session, \"due_date\", value = data[[\"due_date\"]], \"dd-mm-yyyy\")\nupdateDateInput(session, \"actual_date\", value = data[[\"actual_date\"]],\"dd-mm-yyyy\")\n"
> 
> # Same as above but provided to cat for easy viewing
> stackoverflow("https://stackoverflow.com/questions/58248102/date-input-dt-r-shiny") %>%
+   cat
library(shiny)
library(shinyjs)
library(shinythemes)
library(DT)

GetMCATableMetadata <- function() {
  fields <- c(
    id = "Id",
    month = "Month of Account",
    due_date = "Due Date of Submission",
    actual_date = "Actual Date of Submission"
  )

  result <- list(fields = fields)
  return (result)
}


########################## CREATE, READ, UPDATE, DELETE #######################################
#### CRUD



# Find the next ID of a new record
GetMCANextId <- function() {
  if (exists("mcaresponses") && nrow(mcaresponses) > 0) {
    max(as.integer(rownames(mcaresponses))) + 1
  } else {
    return (1)
  }
}

#C
CreateData <- function(data) {
  data <- CastData(data)
  rownames(data) <- GetMCANextId()
  if (exists("mcaresponses")) {
    mcaresponses <<- rbind(mcaresponses, data)
  } else {
    mcaresponses <<- data
  }
}

#R
ReadData <- function() {
  if (exists("mcaresponses")) {
    mcaresponses
  }
}

#U
UpdateData <- function(data) {
  data <- CastData(data)
  mcaresponses[row.names(mcaresponses) == row.names(data),] <<- data
}

#D
DeleteData <- function(data) {
  mcaresponses <<-
    mcaresponses[row.names(mcaresponses) != unname(data["id"]),]
}

#######################################################################################
# Cast from Inputs to a one-row data.frame

CastData <- function(data) {
  datar <- data.frame(
    month = data["month"],
    due_date = as.Date(data[["due_date"]],"dd-mm-yyyy"),
    actual_date = as.Date(data[["actual_date"]],"dd-mm-yyyy")
  )

  rownames(datar) <- data["id"]
  return (datar)
}




# Return an empty, new record
CreateDefaultRecord <- function() {
  mydefault <-
    CastData(list(
      id = "0",
      month = "", 
      due_date ="",
      actual_date=""

    ))
  return (mydefault)
}

# Fill the input fields with the values of the selected record in the table
UpdateInputs <- function(data, session) {
  updateTextInput(session, "id", value = unname(rownames(data)))
  updateTextInput(session, "month", value = unname(data["month"]))
  updateDateInput(session, "due_date", value = as.Date(data[["due_date"]],"dd-mm-yyyy"))
  updateDateInput(session, "actual_date",value=as.Date(data[["actual_date"]],"dd-mm-yyyy"))

}



ui <- fluidPage(
  #use shiny js to disable the ID field
  shinyjs::useShinyjs(),
  ##
  #data table
  DT::dataTableOutput("mcaresponses", width = 800),

  #input fields
  tags$hr(),
  shinyjs::disabled(textInput("id", "Id", "0")),
  textInput("month", "Month of Account", ""),
  dateInput("due_date", label="Due Date of Submission", format="dd-mm-yyyy"),
  dateInput("actual_date", label="Actual Date of Submission", format="dd-mm-yyyy"),
  #action buttons
  actionButton("submit", "Submit"),
  actionButton("new", "New"),
  actionButton("delete", "Delete")
)



server <- function(input, output, session) {
  # input fields are treated as a group
  formData <- reactive({
    sapply(names(GetMCATableMetadata()$fields), function(x)
      input[[x]])
  })

  # Click "Submit" button -> save data
  observeEvent(input$submit, {
    if (input$id != "0") {
      UpdateData(formData())
    } else {
      CreateData(formData())
      UpdateInputs(CreateDefaultRecord(), session)
    }
  }, priority = 1)

  # Press "New" button -> display empty record
  observeEvent(input$new, {
    UpdateInputs(CreateDefaultRecord(), session)
  })

  # Press "Delete" button -> delete from data
  observeEvent(input$delete, {
    DeleteData(formData())
    UpdateInputs(CreateDefaultRecord(), session)
  }, priority = 1)

  # Select row in table -> show details in inputs
  observeEvent(input$mcaresponses_rows_selected, {
    if (length(input$mcaresponses_rows_selected) > 0) {
      data <- ReadData()[input$mcaresponses_rows_selected,]
      UpdateInputs(data, session)
    }

  })

  # display table
  output$mcaresponses <- DT::renderDataTable({
    #update after submit is clicked
    input$submit
    #update after delete is clicked
    input$delete
    ReadData()
    }, server = FALSE, selection = "single",
  colnames = unname(GetMCATableMetadata()$fields)[-1])

}

shinyApp(ui = ui, server = server)


sapply(names(GetMCATableMetadata()$fields), function(x) input[[x]])


CastData

due_date = as.Date(as.numeric(data["due_date"]), origin = "1970-01-01"),
actual_date = as.Date(as.numeric(data["actual_date"]), origin = "1970-01-01")


DateInput

due_date

actual_date

Date

updateDateInput(session, "due_date", value = data[["due_date"]], "dd-mm-yyyy")
updateDateInput(session, "actual_date", value = data[["actual_date"]],"dd-mm-yyyy")
> 
> 
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("stackoverflow", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()

detaching ‘package:dplyr’

> nameEx("tidytext")
> ### * tidytext
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: tidytext
> ### Title: Retrieve raw R code tidytext tutorial
> ### Aliases: tidytext tidytextmining
> 
> ### ** Examples
> 
> library(dplyr)

Attaching package: ‘dplyr’

The following objects are masked from ‘package:stats’:

    filter, lag

The following objects are masked from ‘package:base’:

    intersect, setdiff, setequal, union

> tidytext("https://www.tidytextmining.com/sentiment.html")
[1] "library(tidytext)\n\nget_sentiments(\"afinn\")\n\nget_sentiments(\"bing\")\n\nget_sentiments(\"nrc\")\n\nlibrary(janeaustenr)\nlibrary(dplyr)\nlibrary(stringr)\n\ntidy_books <- austen_books() %>%\n  group_by(book) %>%\n  mutate(linenumber = row_number(),\n         chapter = cumsum(str_detect(text, regex(\"^chapter [\\\\divxlc]\", \n                                                 ignore_case = TRUE)))) %>%\n  ungroup() %>%\n  unnest_tokens(word, text)\n\nnrc_joy <- get_sentiments(\"nrc\") %>% \n  filter(sentiment == \"joy\")\n\ntidy_books %>%\n  filter(book == \"Emma\") %>%\n  inner_join(nrc_joy) %>%\n  count(word, sort = TRUE)\n\nlibrary(tidyr)\n\njane_austen_sentiment <- tidy_books %>%\n  inner_join(get_sentiments(\"bing\")) %>%\n  count(book, index = linenumber %/% 80, sentiment) %>%\n  spread(sentiment, n, fill = 0) %>%\n  mutate(sentiment = positive - negative)\n\nlibrary(ggplot2)\n\nggplot(jane_austen_sentiment, aes(index, sentiment, fill = book)) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~book, ncol = 2, scales = \"free_x\")\n\npride_prejudice <- tidy_books %>% \n  filter(book == \"Pride & Prejudice\")\n\npride_prejudice\n\nafinn <- pride_prejudice %>% \n  inner_join(get_sentiments(\"afinn\")) %>% \n  group_by(index = linenumber %/% 80) %>% \n  summarise(sentiment = sum(value)) %>% \n  mutate(method = \"AFINN\")\n\nbing_and_nrc <- bind_rows(pride_prejudice %>% \n                            inner_join(get_sentiments(\"bing\")) %>%\n                            mutate(method = \"Bing et al.\"),\n                          pride_prejudice %>% \n                            inner_join(get_sentiments(\"nrc\") %>% \n                                         filter(sentiment %in% c(\"positive\", \n                                                                 \"negative\"))) %>%\n                            mutate(method = \"NRC\")) %>%\n  count(method, index = linenumber %/% 80, sentiment) %>%\n  spread(sentiment, n, fill = 0) %>%\n  mutate(sentiment = positive - negative)\n\nbind_rows(afinn, \n          bing_and_nrc) %>%\n  ggplot(aes(index, sentiment, fill = method)) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~method, ncol = 1, scales = \"free_y\")\n\nget_sentiments(\"nrc\") %>% \n     filter(sentiment %in% c(\"positive\", \n                             \"negative\")) %>% \n  count(sentiment)\n\nget_sentiments(\"bing\") %>% \n  count(sentiment)\n\nbing_word_counts <- tidy_books %>%\n  inner_join(get_sentiments(\"bing\")) %>%\n  count(word, sentiment, sort = TRUE) %>%\n  ungroup()\n\nbing_word_counts\n\nbing_word_counts %>%\n  group_by(sentiment) %>%\n  top_n(10) %>%\n  ungroup() %>%\n  mutate(word = reorder(word, n)) %>%\n  ggplot(aes(word, n, fill = sentiment)) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~sentiment, scales = \"free_y\") +\n  labs(y = \"Contribution to sentiment\",\n       x = NULL) +\n  coord_flip()\n\ncustom_stop_words <- bind_rows(tibble(word = c(\"miss\"), \n                                          lexicon = c(\"custom\")), \n                               stop_words)\n\ncustom_stop_words\n\nlibrary(wordcloud)\n\ntidy_books %>%\n  anti_join(stop_words) %>%\n  count(word) %>%\n  with(wordcloud(word, n, max.words = 100))\n\nlibrary(reshape2)\n\ntidy_books %>%\n  inner_join(get_sentiments(\"bing\")) %>%\n  count(word, sentiment, sort = TRUE) %>%\n  acast(word ~ sentiment, value.var = \"n\", fill = 0) %>%\n  comparison.cloud(colors = c(\"gray20\", \"gray80\"),\n                   max.words = 100)\n\nPandP_sentences <- tibble(text = prideprejudice) %>% \n  unnest_tokens(sentence, text, token = \"sentences\")\n\nPandP_sentences$sentence[2]\n\nausten_chapters <- austen_books() %>%\n  group_by(book) %>%\n  unnest_tokens(chapter, text, token = \"regex\", \n                pattern = \"Chapter|CHAPTER [\\\\dIVXLC]\") %>%\n  ungroup()\n\nausten_chapters %>% \n  group_by(book) %>% \n  summarise(chapters = n())\n\nbingnegative <- get_sentiments(\"bing\") %>% \n  filter(sentiment == \"negative\")\n\nwordcounts <- tidy_books %>%\n  group_by(book, chapter) %>%\n  summarize(words = n())\n\ntidy_books %>%\n  semi_join(bingnegative) %>%\n  group_by(book, chapter) %>%\n  summarize(negativewords = n()) %>%\n  left_join(wordcounts, by = c(\"book\", \"chapter\")) %>%\n  mutate(ratio = negativewords/words) %>%\n  filter(chapter != 0) %>%\n  top_n(1) %>%\n  ungroup()"
> 
> # Same as above but provided to cat for easy viewing
> tidytext("https://www.tidytextmining.com/sentiment.html") %>%
+   cat
library(tidytext)

get_sentiments("afinn")

get_sentiments("bing")

get_sentiments("nrc")

library(janeaustenr)
library(dplyr)
library(stringr)

tidy_books <- austen_books() %>%
  group_by(book) %>%
  mutate(linenumber = row_number(),
         chapter = cumsum(str_detect(text, regex("^chapter [\\divxlc]", 
                                                 ignore_case = TRUE)))) %>%
  ungroup() %>%
  unnest_tokens(word, text)

nrc_joy <- get_sentiments("nrc") %>% 
  filter(sentiment == "joy")

tidy_books %>%
  filter(book == "Emma") %>%
  inner_join(nrc_joy) %>%
  count(word, sort = TRUE)

library(tidyr)

jane_austen_sentiment <- tidy_books %>%
  inner_join(get_sentiments("bing")) %>%
  count(book, index = linenumber %/% 80, sentiment) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative)

library(ggplot2)

ggplot(jane_austen_sentiment, aes(index, sentiment, fill = book)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~book, ncol = 2, scales = "free_x")

pride_prejudice <- tidy_books %>% 
  filter(book == "Pride & Prejudice")

pride_prejudice

afinn <- pride_prejudice %>% 
  inner_join(get_sentiments("afinn")) %>% 
  group_by(index = linenumber %/% 80) %>% 
  summarise(sentiment = sum(value)) %>% 
  mutate(method = "AFINN")

bing_and_nrc <- bind_rows(pride_prejudice %>% 
                            inner_join(get_sentiments("bing")) %>%
                            mutate(method = "Bing et al."),
                          pride_prejudice %>% 
                            inner_join(get_sentiments("nrc") %>% 
                                         filter(sentiment %in% c("positive", 
                                                                 "negative"))) %>%
                            mutate(method = "NRC")) %>%
  count(method, index = linenumber %/% 80, sentiment) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative)

bind_rows(afinn, 
          bing_and_nrc) %>%
  ggplot(aes(index, sentiment, fill = method)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~method, ncol = 1, scales = "free_y")

get_sentiments("nrc") %>% 
     filter(sentiment %in% c("positive", 
                             "negative")) %>% 
  count(sentiment)

get_sentiments("bing") %>% 
  count(sentiment)

bing_word_counts <- tidy_books %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  ungroup()

bing_word_counts

bing_word_counts %>%
  group_by(sentiment) %>%
  top_n(10) %>%
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(y = "Contribution to sentiment",
       x = NULL) +
  coord_flip()

custom_stop_words <- bind_rows(tibble(word = c("miss"), 
                                          lexicon = c("custom")), 
                               stop_words)

custom_stop_words

library(wordcloud)

tidy_books %>%
  anti_join(stop_words) %>%
  count(word) %>%
  with(wordcloud(word, n, max.words = 100))

library(reshape2)

tidy_books %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  acast(word ~ sentiment, value.var = "n", fill = 0) %>%
  comparison.cloud(colors = c("gray20", "gray80"),
                   max.words = 100)

PandP_sentences <- tibble(text = prideprejudice) %>% 
  unnest_tokens(sentence, text, token = "sentences")

PandP_sentences$sentence[2]

austen_chapters <- austen_books() %>%
  group_by(book) %>%
  unnest_tokens(chapter, text, token = "regex", 
                pattern = "Chapter|CHAPTER [\\dIVXLC]") %>%
  ungroup()

austen_chapters %>% 
  group_by(book) %>% 
  summarise(chapters = n())

bingnegative <- get_sentiments("bing") %>% 
  filter(sentiment == "negative")

wordcounts <- tidy_books %>%
  group_by(book, chapter) %>%
  summarize(words = n())

tidy_books %>%
  semi_join(bingnegative) %>%
  group_by(book, chapter) %>%
  summarize(negativewords = n()) %>%
  left_join(wordcounts, by = c("book", "chapter")) %>%
  mutate(ratio = negativewords/words) %>%
  filter(chapter != 0) %>%
  top_n(1) %>%
  ungroup()> 
> 
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("tidytext", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> ### * <FOOTER>
> ###
> cleanEx()

detaching ‘package:dplyr’

> options(digits = 7L)
> base::cat("Time elapsed: ", proc.time() - base::get("ptime", pos = 'CheckExEnv'),"\n")
Time elapsed:  1.055 0.061 5.5 0.002 0.002 
> grDevices::dev.off()
null device 
          1 
> ###
> ### Local variables: ***
> ### mode: outline-minor ***
> ### outline-regexp: "\\(> \\)?### [*]+" ***
> ### End: ***
> quit('no')
